{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cec4bed-e08c-4fd9-81b6-b533dd86a917",
   "metadata": {},
   "source": [
    "# Exploring volumetric EM data in Neuroglancer and Dash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5364d5-d71c-4179-9375-4e91f9fc172d",
   "metadata": {},
   "source": [
    "[Neuroglancer](https://github.com/google/neuroglancer) is a WebGL-based viewer developed by Jeremy Maitin-Shephard at the Google Connectomics team to visualize very large volumetric data, designed in large part for connectomics.\n",
    "We often use Neuroglancer to quickly explore data, visualize results in context, and share data.\n",
    "\n",
    "To look at the MICrONS data in Neuroglancer, [click this link](https://neuroglancer.neuvue.io/#!%7B%22jsonStateServer%22:%22https://global.daf-apis.com/nglstate/api/v1/post%22,%22navigation%22:%7B%22pose%22:%7B%22position%22:%7B%22voxelSize%22:%5B4.0,4.0,40.0%5D%7D%7D,%22zoomFactor%22:2.0%7D,%22showSlices%22:false,%22layout%22:%22xy-3d%22,%22perspectiveZoom%22:2000.0,%22layers%22:%5B%7B%22type%22:%22image%22,%22source%22:%22precomputed://https://bossdb-open-data.s3.amazonaws.com/iarpa_microns/minnie/minnie65/em%22,%22name%22:%22img%22,%22shader%22:%22#uicontrol%20float%20black%20slider(min=0,%20max=1,%20default=0.0)%5Cn#uicontrol%20float%20white%20slider(min=0,%20max=1,%20default=1.0)%5Cnfloat%20rescale(float%20value)%20%7B%5Cn%20%20return%20(value%20-%20black)%20/%20(white%20-%20black);%5Cn%7D%5Cnvoid%20main()%20%7B%5Cn%20%20float%20val%20=%20toNormalized(getDataValue());%5Cn%20%20if%20(val%20%3C%20black)%20%7B%5Cn%20%20%20%20emitRGB(vec3(0,0,0));%5Cn%20%20%7D%20else%20if%20(val%20%3E%20white)%20%7B%5Cn%20%20%20%20emitRGB(vec3(1.0,%201.0,%201.0));%5Cn%20%20%7D%20else%20%7B%5Cn%20%20%20%20emitGrayscale(rescale(val));%5Cn%20%20%7D%5Cn%7D%5Cn%22%7D,%7B%22type%22:%22segmentation_with_graph%22,%22source%22:%22graphene://https://minnie.microns-daf.com/segmentation/table/minnie65_public%22,%22name%22:%22seg%22,%22selectedAlpha%22:0.3,%22objectAlpha%22:1.0,%22notSelectedAlpha%22:0.0%7D,%7B%22type%22:%22annotation%22,%22filterBySegmentation%22:false,%22bracketShortcutsShowSegmentation%22:true,%22annotationSelectionShowsSegmentation%22:true,%22name%22:%22ann%22%7D%5D,%22selectedLayer%22:%7B%22layer%22:%22ann%22,%22visible%22:true%7D%7D).\n",
    "\n",
    "Note that you will need to authenticate with the same Google-associated account that you use to set up CAVEclient (if you have already done that)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527c3cd4-42b4-4c31-8d8a-2799d448089e",
   "metadata": {},
   "source": [
    "### Interface Basics\n",
    "\n",
    "The Neuroglancer interface is divided into panels.\n",
    "In the default view, one panel shows the imagery in the X/Y plane (left), one shows a 3d view centered at the same location, and the narrow third panel provides information about the specific layer.\n",
    "Note that at the center of the each panel is a collection of axis-aligned red, blue and, green lines. The intersection and direction of each of these lines is consistent across all panels.\n",
    "\n",
    "Along the top left of the view, you can see tabs with different names.\n",
    "Neuroglancer organizes data into *layers*, where each layer tells Neuroglancer about a different aspect of the data.\n",
    "The default view has three layers:\n",
    "* `img` tells Neuroglancer how to render imagery from a particular cloud location.\n",
    "* `seg` tells Neuroglancer how to render segmentation and meshes from a particular cloud location.\n",
    "* `ann` is a manual annotation layer, allowing the user to add annotations to the data.\n",
    "\n",
    "You can switch between layers by *right clicking* on the layer tab.\n",
    "You will see the panel at the right change to provide controls for each layer as you click it.\n",
    "\n",
    "The collection of all layers, the user view, and all annotations is stored as a JSON object called the **state**.\n",
    "\n",
    "\n",
    "The basic controls for navigation are:\n",
    "* `single click/drag` slides the imagery in X/Y and rotates the 3d view.\n",
    "* `scroll wheel up/down` moves the imagery in Z.\n",
    "* `right click` jumps the 3d view to the clicked location in either the imagery or on a segmented object.\n",
    "* `double click` selects a segmentation and loads its mesh into the 3d view. Double clicking on a selected neuron deselects it.\n",
    "* `control-scrool` zooms the view under the cursor in or out.\n",
    "* `z` snaps the view to the closest right angle.\n",
    "\n",
    "You can paste a position into Neuroglancer by clicking the x, y, z coordinate in the upper left corner and pasting a space or comma-separated list of numbers and hitting enter.\n",
    "Note that Neuroglancer always works in voxel units, and you can see the resolution of the voxels in the extreme upper left corner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40d29a6-018c-4016-b678-50b314a39d98",
   "metadata": {},
   "source": [
    "### Selecting objects\n",
    "\n",
    "The most direct way to select a neuron is to double click in the imagery to select the object under your cursor.\n",
    "This will load all the voxels associated with that object and also display its mesh in the 3d view.\n",
    "\n",
    "To see the list of selected objects, you can select the segmentation tab (right click on the `seg` tab).\n",
    "Underneath the list of options, there is a list of selected root ids and the color assigned to them in the view.\n",
    "You can change colors of all neurons randomly by pressing `l` or individually change colors as desired.\n",
    "In addition, you can press the checkbox to hide a selected object while keeping it in the list, or deselect it by clicking on the number itself.\n",
    "You can also copy a root id by pressing the clipboard icon next to its number, or copy all selected root ids by pressing the clipboard icon above the list.\n",
    "\n",
    "This selection list also allows you to select objects by pasting one or more root ids into the text box at the top of the list and pressing enter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeae245-9c43-4d82-be3c-0232afe5b2e4",
   "metadata": {},
   "source": [
    "### Annotations\n",
    "\n",
    "Annotations are stored in an annotation layer.\n",
    "The default state has an annotation layer called `ann`, but you can always add new annotation layers by command-clicking the `+` button to the right of the layer tabs.\n",
    "\n",
    "To create an annotation, select the layer (right click on the tab), and then click the icon representing the type of annotation you want to use.\n",
    "The most basic annotation is a point, which is the icon to the left of the list.\n",
    "The icon will change to having a green background when selected.\n",
    "\n",
    "Now if you **control-click** in either the imagery or the 3d view, you will create a point annotation at the clicked location.\n",
    "The annotation will appear in the list to the right, with its coordinate (in voxels, not nanometers) displayed.\n",
    "Clicking any annotation in the list will jump to that annotation in 3d space.\n",
    "Each annotation layer can have one color, which you can change with the color picker to the left of the annotation list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50266b5d-bd50-4bcd-bd16-89f2f7d7b74b",
   "metadata": {},
   "source": [
    "### Saving and sharing states\n",
    "\n",
    "Like many other websites that require logins, you cannot simply send your URL ot another person to have them see the view.\n",
    "Instead, to save the current state and make it available to yourself or others in the future, you need to save the state with the `Share` button at the top right corner.\n",
    "This will then give you a URL that you can copy and share with others or paste yourself.\n",
    "A typical sharing URL looks like the following:\n",
    "```\n",
    "https://neuroglancer.neuvue.io/?json_url=https://global.daf-apis.com/nglstate/api/v1/4684616269037568\n",
    "```\n",
    "The first part is the URL for the Neuroglancer viewer, while the part after the `?json_url=` is a URL that points to a JSON file that contains the state.\n",
    "The number at the end of the URL is used to uniquely identify the state and can be used programatically to retrieve information.\n",
    "\n",
    "```{warning}\n",
    "If a URL contains `?local_id=` instead of `?json_url`, that means that it cannot be viewed by anyone else or even in another browser on your own computer.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e335bcc4-1de8-4bdf-8ddc-33a786d37ba9",
   "metadata": {},
   "source": [
    "### Navigating Annotations\n",
    "\n",
    "Annotations in an annotation layer can be right-clicked on to jump to them, but can also be navigated as a list.\n",
    "\n",
    "To see the list of annotations, select the annotation layer (right click on the tab).\n",
    "Each annotation is listed as its location in Neuroglance voxel coordinates.\n",
    "Clicking on an row in this annotation list will not only jump to it in the view, but also select it.\n",
    "You can see the information about the selected neuron in the lower right corner.\n",
    "Once an annotation is selected, any associated root ids are loaded.\n",
    "The keys `[` and `]` will jump to the previous and next annotations in the list, respectively.\n",
    "\n",
    "Each annotation can have a full-text description associated with it for adding notes.\n",
    "This can be added in the lower right corner.\n",
    "\n",
    "However, the most convenient way to label data quickly is through Tags.\n",
    "To add tags, click on the `Shortcuts` tab within the Annotation widget on the right, and then click on the `+` button to add a new tag.\n",
    "Each tag gets a text label and a key command to activate or deactivate it for a given annotation.\n",
    "By default, the first tag is activated by pressing `shift-q`, the second by pressing `shift-w`, and so on down the qwerty line.\n",
    "\n",
    "Now when you select an annotation, you can press the key command to attach that tag to it.\n",
    "Pressing the same key command will remove the tag.\n",
    "Any number of tags can be added to each annotation.\n",
    "Together with the `[` and `]` keys to navigate the list, this allows you to quickly label a large number of annotations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8373e2-fdf5-44b0-8894-3b6de2b22129",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "Let's start looking at cells with fresh eyes. \n",
    "\n",
    "- Start with one neuron with a root id [from this google sheet](https://docs.google.com/spreadsheets/d/1adZ6f8zx691_mgQxFlTHUI0mhlNiIDtyobdt6CSVNBM/edit?usp=sharing).\n",
    "- Identify the soma, dendrite, and axon initial segment.\n",
    "- Starting with the soma, look around at the shape of the soma in 3d and in the ultrastructure. What types of objects do you notice? Are there things you recognize or don't recognize?\n",
    "- Add point annotations on interesting objects and label them with a description.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bf12e7-d6de-4ee5-b95e-246b8e88ffe1",
   "metadata": {},
   "source": [
    "### Annotations from Dash Apps\n",
    "\n",
    "We have created two webapps to help explore and visualize the data.\n",
    "These apps were created using the [Dash](https://plotly.com/dash/) framework, hence the name.\n",
    "\n",
    "## Table Viewer\n",
    "\n",
    "The [**Table Viewer**](https://minnie.microns-daf.com/dash/datastack/minnie65_public/apps/table_viewer/?datastack=%22minnie65_public%22) app allows you to query individual tables in the database, filter them, and visualize the results in Neuroglancer.\n",
    "\n",
    "In the Table Viewer, you first select one of the tables from a dropdown in the upper left side.\n",
    "The `Live Query` option is not relevent for the public data.\n",
    "Filter options allow you to limit the query to a subset of the data, if desired.\n",
    "Note that filtering can occur in the tables afterward as well.\n",
    "The `Cell IDs` field lets you put in one or more root IDs, cell IDs (i.e. \"Nucleus ID\"), or IDs from the annotation table being queried.\n",
    "Note that if you use this option, you havet o set the dropdown to the appropriate ID type.\n",
    "The `Value Search` field lets you search for a particular value, such as a specific cell type.\n",
    "\n",
    "Once you have selected your table and set any pre-query filters, click the `Submit` button to run the query.\n",
    "When the query is done, a green bar will appear below the query input stating that it's showing the state of the table you queried.\n",
    "The first set of controls allow you to build a Neuroglancer link for the whole table using the \"Generate Link\" button.\n",
    "Optionally, if you would like to make a link where different values of a given column — example, different cell types — are shown in different layers, you can turn on the \"Group Annotations\" toggle on the right and select the column you want to use for groupings.\n",
    "After setting these controls, click the \"Generate Link\" button to create the Neuroglancer link.\n",
    "\n",
    "The table itself is shown below the controls.\n",
    "You can sort the table by clicking on the column headers, and filter the table by typing in the filter box below the column headers.  \n",
    "For example, if you want to find only cells with cell type \"5P-NP\" in a cell type column, simply type `5P-NP` in the box under the column header. Similarly, to find only cells whose nucleus volume is greater than 500, type `>500` in the box under the `volume` column header in a table with nucleus information.\n",
    "In addition, individual rows can be selected by clicking on the checkbox to the left of the row.\n",
    "The left button along the top is a Neuroglancer link specific to the selected rows, if present, or the table as filtered if no rows are selected.\n",
    "The orange button will deselect all checkboxes, and the \"Export to CSV\" will download the table as filtered to a CSV.\n",
    "\n",
    "```{important}\n",
    "If the table is too large (well beyond 10,000 rows), there are too many annotations to show in Neuroglancer and no link will be automatically generated.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cd1698-fa9d-4821-8e15-97b049bd3957",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "Let's start looking at cells with fresh eyes. \n",
    "\n",
    "- Start with one neuron with a root id [from this google sheet](https://docs.google.com/spreadsheets/d/1adZ6f8zx691_mgQxFlTHUI0mhlNiIDtyobdt6CSVNBM/edit?usp=sharing).\n",
    "- Identify the soma, dendrite, and axon initial segment.\n",
    "- Starting with the soma, look around at the shape of the soma in 3d and in the ultrastructure. What types of objects do you notice? Are there things you recognize or don't recognize?\n",
    "- Add point annotations on interesting objects and label them with a description.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b8b782-16e1-4d08-bd7f-0f86014ea133",
   "metadata": {},
   "source": [
    "### Connectivity and Cell Type Viewer\n",
    "\n",
    "The other tool is the [**Connectivity Viewer**](https://minnie.microns-daf.com/dash/datastack/minnie65_public/apps/connectivity/?datastack=%22minnie65_public%22), which is designed to let you glance at the synaptic output or input of a given cell and group connectivity by cell type or other annotations.\n",
    "\n",
    "Along the top, you can enter an ID (either a root ID or a cell ID) and, optionally, a table to use to define cell types for synaptic partners.\n",
    "Note that if you want to use cell IDs from the annotation table, you must select the `Nucleus ID` option from the dropdown next to the entry box.\n",
    "The default cell type table option, `aibs_soma_nuc_metamodel_preds_v117`, is a good all-purpose table predicting coarse cell types on as many cells as possible.\n",
    "\n",
    "Pressing \"Submit\" will query the database for the cell and its synapses.\n",
    "Once completed, you will see the bar under the input options turn green and report the data that it is displaying.\n",
    "For example, if we query root id `864691135408247241`` and the default cell type table, we will see the following:\n",
    "\n",
    "Importantly, the data displayed below will match whatever is in this bar — if your query takes a long time or fails for some reason (i.e.bad internet, server error), the tables displayed might be stale.\n",
    "\n",
    "There are two locations the resulting data is displayed.\n",
    "First, a bar of tabs allows you to quickly visualize the data in different ways.\n",
    "Second, the table can present synaptic partners in a more detailed way.\n",
    "\n",
    "### Visualization tabs\n",
    "\n",
    "The first and default option in the tabs is **Tables Only** which doesn't actually show any data.\n",
    "This is merely a placeholder to let you look directly at the tablular data below.\n",
    "\n",
    "The next tab, **Plots** lets you visualize the synaptic output of a neuron.\n",
    "We focus on synaptic output only right now, because the data quality is such that automated dendritic reconstructions are reliable, but automated axon reconstructions are not (see [Proofreading section](em:proofreading-data-quality)).\n",
    "Because of that, if a neuron has been proofread we trust the cell types of its postsynaptic partners as a group but do not trust the cell types of its presynaptic partners.\n",
    "\n",
    "These plots are designed to give you a quick overview of a cell's synaptic outputs.\n",
    "To add a particularly cell type column, use the `Color by value:` dropdown below the row of plots to select a column to color by.\n",
    "These plots are handled in [Plotly](https://plotly.com/python/), so you can hover over the plots to see more information, and you can click and drag to zoom in on a particular region and save by clicking on the camera icon. For the scatterplot, you can also turn on and off individual types by clicking on the legend.\n",
    "\n",
    "The next tab, **Neuroglancer Links** lets you visualize the synapses of a neuron in Neuroglancer.\n",
    "\n",
    "The Neuroglancer links generated by these buttons will span all synapses of the queried cell, and do not reflect the filtering in the table below.\n",
    "The synapse annotations are also associated with the synaptic partners, making it easy to browse through a broad sampling of synaptic connectivity.\n",
    "\n",
    "### Connectivity Table\n",
    "\n",
    "The table shows a table of all synaptic partners.\n",
    "\n",
    "One of the first things you can see in the table viewer is that it is split into two tabs, **Input** and **Output**, with the tab names for each showing the total number of synapses in each category.\n",
    "To move between them, just click the tab you want.\n",
    "Above the Input/Ouput tabs is a link to the Neuroglancer view of the synapses show in the table, after filtering and/or selecting a subset of rows.\n",
    "The table view here is similar to in the Annotation Table Viewer described above.\n",
    "You can sort the table by clicking column headers, filter the table using the row underneath the headers, and select individual rows.\n",
    "If you select individual rows, the Neuroglancer link will group all synapses from each partner together, making it particularly easy to see how synaptic connectivity relates to neuronal anatomy.\n",
    "\n",
    "The default sorting of the table is by total number of synapses, but note that both summed total synapse size (`net_size`) and average synapse size (`mean_size`) are also shown.\n",
    "These can be particularly important values when thinking about connectivity between excitatory neurons.\n",
    "\n",
    "A CSV file of the entire table can be downloaded by clicking the \"Export to CSV\" button.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5893c0-ab44-4817-af96-6bb01dcdc35d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis_m1",
   "language": "python",
   "name": "analysis_m1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
