{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a342c5b7",
   "metadata": {},
   "source": [
    "# Visualizing and Analyzing Meshes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c09007",
   "metadata": {},
   "source": [
    "When trying to understand the fine 3d morphology of a neuron (e.g. features under 1 micron in scale), meshes are a particularly useful representation. More precisely, a mesh is a collection of vertices and faces that define a 3d surface. The exact meshes that one sees in Neuroglancer can also be loaded for analysis and visualization in other tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deeab79",
   "metadata": {},
   "source": [
    "# Downloading Meshes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c291ca",
   "metadata": {},
   "source": [
    "The easiest tool for downloading MICrONs meshes is [Meshparty](https://github.com/sdorkenw/MeshParty), which is a python module that can be installed with `pip install meshparty`. Documentation for Meshparty can be found here.\n",
    "\n",
    "Once installed, the typical way of getting meshes is by using a “MeshMeta” client that is told both the internet location of the meshes (`cv_path`) and a local directory in which to store meshes (`disk_cache_path`). Once initialized, the MeshMeta client can be used to download meshes for a given segmentation using its root id (`seg_id`). The following code snippet shows how to download an example mesh using a directory “meshes” as the local storage folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83963dc5",
   "metadata": {},
   "source": [
    "### Why MeshMeta?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cda682",
   "metadata": {},
   "source": [
    "One convenience of using the `MeshMeta` approach is that if you have already downloaded a mesh for with a given root id, it will be loaded from disk rather than re-downloaded.\n",
    "\n",
    "If you have to download many meshes, it is somewhat faster to use the bulk `download_meshes` function and use multiple threads via the `n_threads` argument. If you download them to the same folder used for the MeshMeta object, they can be loaded through the same interface.\n",
    "\n",
    "#### Note: Meshes can be hundreds of megabytes in size, so be careful about downloading too many if the internet is not acting well or your computer doesn’t have much disk space!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a445f4e1",
   "metadata": {},
   "source": [
    "# Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb5c0b0",
   "metadata": {},
   "source": [
    "Meshes have a large number of properties, many of which come from being based on the [Trimesh](https://trimsh.org/) library’s mesh format, and others being specific to MeshParty.\n",
    "\n",
    "Several of the most important properties are:\n",
    "\n",
    "- `mesh.vertices` : An `N x 3` list of vertices and their 3d location in nanometers, where N is the number of vertices.\n",
    "\n",
    "- `mesh.faces` : An `P x 3` list of integers, with each row specifying a triangle of connected vertex indices.\n",
    "\n",
    "- `mesh.edges` : An `M x 2` list of integers, with each row specifying a pair of connected vertex indices based off of faces.\n",
    "\n",
    "- `mesh.link_edges` : An `M_l x 2` list of integers, with each row specifying a pair of “link edges” that were used to heal gaps based on proofreading edits.\n",
    "\n",
    "- `mesh.graph_edges` : An `(M+M_l) x 2` list of integers, with each row specifying a pair of graph edges, which is the collection of both mesh.edges and `mesh.link_edges`.\n",
    "\n",
    "- `mesh.csgraph` : A [Scipy Compressed Sparse Graph](https://docs.scipy.org/doc/scipy/reference/sparse.csgraph.html) representation of the mesh as an `NxN` graph of vertices connected to one another using graph edges and with edge weights being the distance between vertices. This is particularly useful for computing shortest paths between vertices.\n",
    "\n",
    "\n",
    "#### Important: \n",
    "MICrONs meshes are not generally “watertight”, a property that would enable a number of properties to be computed natively by Trimesh. Because of this, Trimesh-computed properties relating to solid forms or volumes like `mesh.volume` or `mesh.center_mass` do not have sensible values and other approaches should be taken. Unfortunately, because of the Trimesh implementation of these properties it is up to the user to be aware of this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e1b30e",
   "metadata": {},
   "source": [
    "# Visualizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f72d72",
   "metadata": {},
   "source": [
    "There are a variety of tools for visualizing meshes in python. MeshParty interfaces with VTK, a powerful but complex data visualization library that does not always work well in python. The basic pattern for MeshParty’s VTK integration is to create one or more “actors” from the data, and then pass those to a renderer that can be displayed in an interactive approach. The following code snippet shows how to visualize a mesh using this approach.\n",
    "\n",
    "#### Note: By default, neurons will appear upside down because the coordinate system of the dataset has the y-axis value increasing along the “downward” pia to white matter axis. More documentation on the MeshParty VTK visualization can be [found here](https://meshparty.readthedocs.io/en/latest/source/meshparty.html).\n",
    "\n",
    "Other tools worth exploring are [PyVista](https://docs.pyvista.org/), [Polyscope](https://polyscope.run/), [Vedo](https://vedo.embl.es/), [MeshLab](https://www.meshlab.net/), and if you have some existing experience, [Blender](https://www.blender.org/) (see Blender integration by our friends behind [Navis](https://navis.readthedocs.io/en/latest/source/blender.html), a fly-focused framework analyzing connectomics data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbc8f02",
   "metadata": {},
   "source": [
    "# Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a0b24f",
   "metadata": {},
   "source": [
    "One of the most common operations on meshes is to mask them to a particular region of interest. This can be done by “masking” the mesh with a boolean array of length `N` where `N` is the number of vertices in the mesh, with `True` where the vertex should be kept and `False` where it should be omitted. There are several convenience functions to generate common masks in the [Mesh Filters](https://meshparty.readthedocs.io/en/latest/source/meshparty.html#module-meshparty.mesh_filters) module.\n",
    "\n",
    "In the following example, we will first mask out all vertices that aren’t part of the largest connected component of the mesh (i.e. get rid of floating vertices that might arise due to internal surfaces) and then mask out all vertices that are more than 15,000 nm away from the soma center."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f08ea5",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0534111",
   "metadata": {},
   "source": [
    "- Start with one neuron with a root id [from this google sheet](https://docs.google.com/spreadsheets/d/1adZ6f8zx691_mgQxFlTHUI0mhlNiIDtyobdt6CSVNBM/edit?usp=sharing).\n",
    "- Download the mesh using meshparty\n",
    "- Using trimesh_vtk, create a mesh actor and render your mesh of interest. What do you notice? Are there any artifacts that look suspicious? Would you feel confident extracting shape, size, and other morphological features from this object?\n",
    "- Using mesh_filters, filter your mesh for the largest component and visualize it using vtk and compare the meshes before and after filtering.\n",
    "\n",
    "#### Tip 1: To double check you have the right neuron, use your experience from session 1 to visualize your neuron in Neuroglancer.\n",
    "\n",
    "#### Tip 2: When inspecting your mesh, it can be helpful to lower the opacity of your mesh to see any internal surfaces present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83200a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from meshparty import trimesh_io, mesh_filters\n",
    "from caveclient import CAVEclient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ae52d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1682e35d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cb66cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10fb3b0a",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab404179",
   "metadata": {},
   "source": [
    "- Using your mesh from Task 1, use mask filtering to get a 150,000nm cutout around the soma\n",
    "- Visualize this cutout and ensure it looks correct. What ultrastructural features are available to you just from the mesh? Is there anything you would like to measure?\n",
    "- What is the area and volume of you cutout?\n",
    "- Now that you have done this for one cell, do any of the metrics you've measure vary across cells?\n",
    "\n",
    "#### Tip 1: Remember that meshes need to be watertight in order to trust the volume and area measurements\n",
    "\n",
    "\n",
    "#### Bonus Task: \n",
    "- What about synapses? Can you query your cell of interest and measure the density of synapses within 15 microns of the cell's soma center?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a1140b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd4428b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867d0bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
